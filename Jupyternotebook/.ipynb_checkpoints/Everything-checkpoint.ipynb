{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Correct Car in the Spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kunal/Documents/Cardetection/PersonalData/frame12.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(path)\n",
    "w1, h1 = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((int(w1/2),int(h1/2)),Image.ANTIALIAS)\n",
    "img.save(\"/Users/kunal/Documents/Cardetection/image_scaled.jpg\",quality=95)\n",
    "img.save(\"/Users/kunal/Documents/Cardetection/image_scaled_opt.jpg\",optimize=True,quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kunal/Documents/Cardetection/image_scaled_opt.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "from google.cloud import vision\n",
    "import io\n",
    "from google.oauth2 import service_account\n",
    "import us\n",
    "import webcolors\n",
    "import binascii\n",
    "import struct\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import imageio\n",
    "# Importing the modules for collecting and building the dataset\n",
    "\"\"\"import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Web-scraping...\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.request import URLError, HTTPError\n",
    "\"\"\"\n",
    "# Image processing...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from autocorrect import Speller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lisence Plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Using GoogleAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kunal/Documents/Cardetection/image_scaled_opt.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '/Users/kunal/Documents/Cardetection/GOOGLEAPI/key.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(key)\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_python_migration_text_detection]\n",
    "with io.open(path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolygonArea(corners):\n",
    "    n = len(corners) # of corners\n",
    "    area = 0.0\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        area += corners[i][0] * corners[j][1]\n",
    "        area -= corners[j][0] * corners[i][1]\n",
    "    area = abs(area) / 2.0\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "w, h, dis = img.shape\n",
    "areaTotal = w*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "count = 1\n",
    "for text in texts:\n",
    "    verticeArray=[]\n",
    "    for vertex in text.bounding_poly.vertices:\n",
    "        verticeSingle = (vertex.x, vertex.y)\n",
    "        verticeArray.append(verticeSingle) \n",
    "    area = PolygonArea(verticeArray)\n",
    "    percent = ((area/areaTotal)*100)\n",
    "    totalText = [text.description, verticeArray, area, percent]\n",
    "    \n",
    "    result.append(totalText)\n",
    "    count+=1\n",
    "    #print(\"\\n\")\n",
    "if response.error.message:\n",
    "    print(response.error.message)\n",
    "    print(\"NOTHINGDETECTED\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv2.rectangle(img, (520, 802),(706, 793), (255,0,0), 2)\n",
    "cv2.imshow(\"lalala\", img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv.polylines(img,[pts],True,(0,255,255))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "for c in cnts:\n",
    "    cv2.drawContours(image, result[1][1], -1, (255,255,255), -1)\n",
    "cv2.imshow('image', image)\n",
    "cv2.resizeWindow('image', 600,600)\n",
    "\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDetectionArray = []\n",
    "for i in result:\n",
    "    stateDetectionArray.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyList = [\"Fulton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=0\n",
    "removeARRAY = []\n",
    "for i in stateDetectionArray:\n",
    "    for j in us.states.STATES:\n",
    "        if spell(i.lower()) == str(j).lower():\n",
    "            removeARRAY.append(i)\n",
    "    for k in countyList:\n",
    "        if spell(i.lower()) == k.lower():\n",
    "            removeARRAY.append(i)\n",
    "    if len(i) > 9:\n",
    "        removeARRAY.append(i)\n",
    "    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeARRAY = list(set(removeARRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultClean = result\n",
    "num = 0\n",
    "for i in result: \n",
    "    for j in removeARRAY:\n",
    "        if i[0] == j:\n",
    "            resultClean.pop(num)\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "perArrayRemove = []\n",
    "for i in resultClean:\n",
    "    if i[3] < 1:\n",
    "        perArrayRemove.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctFR = 0\n",
    "for i in result:\n",
    "    for j in perArrayRemove:\n",
    "        if i == j:\n",
    "            resultClean.pop(ctFR)\n",
    "    ctFR+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISENCEPLATE =\"\"\n",
    "if len(resultClean) == 1:\n",
    "    LISENCEPLATE = resultClean[0][0]\n",
    "elif len(resultClean) > 1:\n",
    "    print(\"CHECK\")\n",
    "    LISENCEPLATE = \"Check\"\n",
    "else:\n",
    "    LISENCEPLATE = \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RFY7228'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LISENCEPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit if GoogleAPI DIDNT WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_contour_precedence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(img):\n",
    "    \"\"\"\n",
    "    This function resize non square image to square one (height == width)\n",
    "    :param img: input image as numpy array\n",
    "    :return: numpy array\n",
    "    \"\"\"\n",
    "    # image after making height equal to width\n",
    "    squared_image = img\n",
    "\n",
    "    # Get image height and width\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "\n",
    "    # In case height superior than width\n",
    "    if h > w:\n",
    "        diff = h-w\n",
    "        if diff % 2 == 0:\n",
    "            x1 = np.zeros(shape=(h, diff//2))\n",
    "            x2 = x1\n",
    "        else:\n",
    "            x1 = np.zeros(shape=(h, diff//2))\n",
    "            x2 = np.zeros(shape=(h, (diff//2)+1))\n",
    "\n",
    "        squared_image = np.concatenate((x1, img, x2), axis=1)\n",
    "\n",
    "    # In case height inferior than width\n",
    "    if h < w:\n",
    "        diff = w-h\n",
    "        if diff % 2 == 0:\n",
    "            x1 = np.zeros(shape=(diff//2, w))\n",
    "            x2 = x1\n",
    "        else:\n",
    "            x1 = np.zeros(shape=(diff//2, w))\n",
    "            x2 = np.zeros(shape=((diff//2)+1, w))\n",
    "\n",
    "        squared_image = np.concatenate((x1, img, x2), axis=0)\n",
    "\n",
    "    return squared_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(vector):\n",
    "    sort = True\n",
    "    while (sort == True):\n",
    "\n",
    "        sort = False\n",
    "        for i in range(len(vector) - 1):\n",
    "            x_1 = vector[i][0]\n",
    "            y_1 = vector[i][1]\n",
    "\n",
    "            for j in range(i + 1, len(vector)):\n",
    "\n",
    "                x_2 = vector[j][0]\n",
    "                y_2 = vector[j][1]\n",
    "\n",
    "                if (x_1 >= x_2 and y_2 >= y_1):\n",
    "                    tmp = vector[i]\n",
    "                    vector[i] = vector[j]\n",
    "                    vector[j] = tmp\n",
    "                    sort = True\n",
    "\n",
    "                elif (x_1 < x_2 and y_2 > y_1):\n",
    "                    tmp = vector[i]\n",
    "                    vector[i] = vector[j]\n",
    "                    vector[j] = tmp\n",
    "                    sort = True\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plate_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_segmentation(img_file_path):\n",
    "\n",
    "    img = cv2.imread(img_file_path)\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    area = height * width\n",
    "\n",
    "    scale1 = 0.001\n",
    "    scale2 = 0.1\n",
    "    area_condition1 = area * scale1\n",
    "    area_condition2 = area * scale2\n",
    "    # global thresholding\n",
    "    ret1,th1 = cv2.threshold(imgray,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    # Otsu's thresholding\n",
    "    ret2,th2 = cv2.threshold(imgray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    # Otsu's thresholding after Gaussian filtering\n",
    "    blur = cv2.GaussianBlur(imgray,(5,5),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    image, contours, hierarchy = cv2.findContours(th3, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # sort contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    cropped = []\n",
    "    for cnt in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "\n",
    "\n",
    "        if (w * h > area_condition1 and w * h < area_condition2 and w/h > 0.3 and h/w > 0.3):\n",
    "            cv2.drawContours(img, [cnt], 0, (0, 255, 0), 3)\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (255, 0, 0), 2)\n",
    "            c = th2[y:y+h,x:x+w]\n",
    "            c = np.array(c)\n",
    "            c = cv2.bitwise_not(c)\n",
    "            c = square(c)\n",
    "            c = cv2.resize(c,(28,28), interpolation = cv2.INTER_AREA)\n",
    "            cropped.append(c)\n",
    "    cv2.imwrite('detection.png', img)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LISENCEPLATE == \"N/A\":\n",
    "    model = load_model('/Users/kunal/Documents/Cardetection/RecognizeLisencePlate/cnn_classifierNew.h5')\n",
    "    digits = plate_segmentation(path)\n",
    "    final_Array = []\n",
    "    for d in digits:\n",
    "        d = np.reshape(d, (1,28,28,1))\n",
    "        out = model.predict(d)\n",
    "        # Get max pre arg\n",
    "        p = []\n",
    "        precision = 0\n",
    "        for i in range(len(out)):\n",
    "            z = np.zeros(36)\n",
    "            z[np.argmax(out[i])] = 1.\n",
    "            precision = max(out[i])\n",
    "            p.append(z)\n",
    "        prediction = np.array(p)\n",
    "\n",
    "        # Inverse one hot encoding\n",
    "        alphabets = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "        classes = []\n",
    "        for a in alphabets:\n",
    "            classes.append([a])\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', categorical_features=None)\n",
    "        ohe.fit(classes)\n",
    "        pred = ohe.inverse_transform(prediction)\n",
    "        if precision > 0.85:\n",
    "            final_Array.append(pred)\n",
    "        if precision > 0.85:\n",
    "            print('Prediction : ' + str(pred[0][0]) + ' , Precision : ' + str(precision))\n",
    "    finalstring = \"\"\n",
    "    for i in final_Array:\n",
    "        finalstring += i[0][0]\n",
    "    print(finalstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image\n",
      "Finding clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: scipy.product is deprecated and will be removed in SciPy 2.0.0, use numpy.product instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centres:\n",
      " [[203.3820132  204.2879538  210.39933993]\n",
      " [248.93289474 250.53421053 248.50921053]\n",
      " [ 79.08206897  77.69931034  79.96551724]\n",
      " [137.07436709 138.6835443  145.91297468]\n",
      " [108.83359302  85.44032409  70.54160175]\n",
      " [ 47.79635902  44.67400508  46.48814564]\n",
      " [107.7720524  107.49650655 113.8069869 ]\n",
      " [ 63.90177997  62.3156766   62.80120094]\n",
      " [ 91.23292308  90.87907692  95.72553846]\n",
      " [170.59328969 172.16448445 178.84042553]]\n",
      "Most frequent is [63.90177997 62.3156766  62.80120094] (#3f3e3e)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: scipy.histogram is deprecated and will be removed in SciPy 2.0.0, use numpy.histogram instead\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: scipy.argmax is deprecated and will be removed in SciPy 2.0.0, use numpy.argmax instead\n"
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS = 10\n",
    "\n",
    "print('Reading image')\n",
    "im = Image.open(path)\n",
    "im = im.resize((150, 150))      # optional, to reduce time\n",
    "ar = np.asarray(im)\n",
    "shape = ar.shape\n",
    "ar = ar.reshape(scipy.product(shape[:2]), shape[2]).astype(float)\n",
    "\n",
    "print('Finding clusters')\n",
    "codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "print('Cluster centres:\\n', codes)\n",
    "\n",
    "vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "\n",
    "index_max = scipy.argmax(counts)                    # find most frequent\n",
    "peak = codes[index_max]\n",
    "colour = binascii.hexlify(bytearray(int(c) for c in peak)).decode('ascii')\n",
    "print('Most frequent is %s (#%s)' % (peak, colour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = int(peak[0])\n",
    "g = int(peak[1])\n",
    "b = int(peak[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET = '\\033[0m'\n",
    "def get_color_escape(r, g, b, background=False):\n",
    "    return '\\033[{};2;{};{};{}m'.format(48 if background else 38, r, g, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLOR DETECTED\n",
      "\u001b[38;2;63;62;62m\u001b[48;2;63;62;62m-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"COLOR DETECTED\")\n",
    "print(get_color_escape(r, g, b) \n",
    "      + get_color_escape(r, g, b, True)\n",
    "      + (\"\"+\"-\"*35+'\\n')*8\n",
    "      + RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual colour name: None , closest colour name: darkslategrey\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "def get_colour_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = webcolors.rgb_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "requested_colour = (r, g, b)\n",
    "actual_name, closest_name = get_colour_name(requested_colour)\n",
    "\n",
    "print (\"Actual colour name:\", actual_name, \", closest colour name:\", closest_name)\n",
    "COLORNAME1 = actual_name\n",
    "COLORNAME2 = closest_name\n",
    "if COLORNAME1 != \"\":\n",
    "    COLORNAME1 = \"N/A\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# bonus: save image using only the N most common colours\n",
    "c = ar.copy()\n",
    "for i, code in enumerate(codes):\n",
    "    c[scipy.r_[scipy.where(vecs==i)],:] = code\n",
    "imageio.imwrite('clusters.png', c.reshape(*shape).astype(np.uint8))\n",
    "print('saved clustered image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = ['Alfa Romeo', 'Audi', 'BMW', 'Chevrolet', 'Citroen', 'Dacia', 'Daewoo', 'Dodge',\n",
    "        'Ferrari', 'Fiat', 'Ford', 'Honda', 'Hyundai', 'Jaguar', 'Jeep', 'Kia', 'Lada',\n",
    "        'Lancia', 'Land Rover', 'Lexus', 'Maserati', 'Mazda', 'Mercedes', 'Mitsubishi',\n",
    "        'Nissan', 'Opel', 'Peugeot', 'Porsche', 'Renault', 'Rover', 'Saab', 'Seat',\n",
    "        'Skoda', 'Subaru', 'Suzuki', 'Tata', 'Tesla', 'Toyota', 'Volkswagen', 'Volvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/Users/kunal/Documents/Cardetection/Jupyternotebook/symbolMODEL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_x = img_y = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will need that later to re-convert my flattened images to their previous state\n",
    "def ImageConvert(n, i):\n",
    "    im_ex = i.reshape(n, img_x, img_y, 3)\n",
    "    im_ex = im_ex.astype('float32') / 255\n",
    "    im_ex = np.subtract(im_ex, 0.5)\n",
    "    im_ex = np.multiply(im_ex, 2.0)\n",
    "    return im_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(path).convert(\"RGB\")\n",
    "new_im = np.array(im.resize((50,50))).flatten()\n",
    "m = int(model.predict_classes(ImageConvert(1, new_im), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGODETECTED = cars[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTED A CAR WITH:\n",
      " ************************************************** \n",
      "\tLISENCE PLATE:  RFY7228\n",
      "\tCOLOR A:  N/A\n",
      "\tCOLOR B:  darkslategrey\n",
      "\tLOGO:  Porsche\n"
     ]
    }
   ],
   "source": [
    "print(\"DETECTED A CAR WITH:\\n\",\"*\"*50,  \"\\n\\tLISENCE PLATE: \", LISENCEPLATE)\n",
    "print(\"\\tCOLOR A: \", COLORNAME1)\n",
    "print(\"\\tCOLOR B: \", COLORNAME2)\n",
    "print(\"\\tLOGO: \", LOGODETECTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
