{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = 'gs://cloud-samples-data/vision/using_curl/shanghai.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file(\"key.json\")\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = vision.types.Image()\n",
    "image.source.image_uri = image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.label_detection(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (and confidence score):\n",
      "===============================================================================\n",
      "People (95.05%)\n",
      "Street (89.12%)\n",
      "Mode of transport (89.09%)\n",
      "Transport (85.13%)\n",
      "Vehicle (84.69%)\n",
      "Snapshot (84.11%)\n",
      "Urban area (80.29%)\n",
      "Infrastructure (73.14%)\n",
      "Road (72.74%)\n",
      "Pedestrian (68.90%)\n"
     ]
    }
   ],
   "source": [
    "print('Labels (and confidence score):')\n",
    "print('=' * 79)\n",
    "for label in response.label_annotations:\n",
    "    print(f'{label.description} ({label.score*100.:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kunal/Documents/Cardetection/frame5.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts:\n",
      "\n",
      "\"Ston GEORGIA\n",
      "RFY7228\n",
      "FULTON\n",
      "\"\n",
      "bounds: (449,772),(1130,772),(1130,1151),(449,1151)\n",
      "\n",
      "\"Ston\"\n",
      "bounds: (520,802),(706,793),(710,871),(524,880)\n",
      "\n",
      "\"GEORGIA\"\n",
      "bounds: (711,792),(1127,772),(1130,851),(715,871)\n",
      "\n",
      "\"RFY7228\"\n",
      "bounds: (449,895),(1111,878),(1116,1078),(454,1095)\n",
      "\n",
      "\"FULTON\"\n",
      "bounds: (722,1112),(840,1109),(841,1148),(723,1151)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Detects text in the file.\"\"\"\n",
    "from google.cloud import vision\n",
    "import io\n",
    "credentials = service_account.Credentials.from_service_account_file(\"key.json\")\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "# [START vision_python_migration_text_detection]\n",
    "with io.open(path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "print('Texts:')\n",
    "\n",
    "for text in texts:\n",
    "    print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "if response.error.message:\n",
    "    raise Exception(\n",
    "        '{}\\nFor more info on error messages, check: '\n",
    "        'https://cloud.google.com/apis/design/errors'.format(\n",
    "            response.error.message))\n",
    "# [END vision_python_migration_text_detection]\n",
    "# [END vision_text_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath = '/Users/kunal/Documents/Cardetection/frame5.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "credentials = service_account.Credentials.from_service_account_file(\"key.json\")\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "with open(imagepath, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "response = client.logo_detection({'content': content,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logo_annotations {\n",
       "  mid: \"/m/017yh\"\n",
       "  description: \"BMW\"\n",
       "  score: 0.9803694486618042\n",
       "  bounding_poly {\n",
       "    vertices {\n",
       "      x: 610\n",
       "      y: 486\n",
       "    }\n",
       "    vertices {\n",
       "      x: 923\n",
       "      y: 486\n",
       "    }\n",
       "    vertices {\n",
       "      x: 923\n",
       "      y: 771\n",
       "    }\n",
       "    vertices {\n",
       "      x: 610\n",
       "      y: 771\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageAnnotatorClient' object has no attribute 'landmark_annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bdd93ea9bd2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageAnnotatorClient' object has no attribute 'landmark_annotations'"
     ]
    }
   ],
   "source": [
    "response = client.landmark_annotations({'content': content,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
